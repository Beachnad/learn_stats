---
title: "Chi-Squared Test"
output: html_document
---

`r (knitr::opts_chunk$set(collapse=T))`

# Introduction

There are many kinds of tests related to chi-squared, and in this document, I will cover the following:

- Pearson chi-squared - test of fit
- chi-squared - test of indendence

# Pearson Chi-Squared (Test of Fit)


## Lesson Plan

This code was generated by following the video here: (Khan Academy)[https://www.youtube.com/watch?v=2QeDRsxSF9M]

The libraries needed for this lesson
```{r message=F, warning=F}
library(dplyr)
library(ggplot2)
```

## What is it?

Chi-Squared test is how we can check if two given distributions of categorical data are statistically equivalent. For example, if given the percentage of people who wear a rain jecket on a given day might be 85% of people do wear a jacket and 15% of people do not, we can test if our observations fit this distribution. If we go out on a rainy day and record that 23 people were wearing rain jacket and 4 people were not, this test will tell use if our observations fit the hypothesis stated previously.

## Example

A resturaunt owner gives us what percentage of his total customers arrive at his resturant for each day of the week. We think that he is wrong, so we collect our own data to test.

In term of our hypothesis:

- H<sub>0</sub>: Owner's distribution is correct
- H<sub>1</sub>: Owner's distribution is not correct

```{r}
data <- tibble(
  day_of_wk = c('Monday', 'Tuesday', 'Wednesday', 'Thusday', 'Friday', 'Saturday'),
  # The percentage of the owner's reported customers
  owner = c(0.10, 0.10, 0.15, 0.20, 0.30, 0.15),
  # our observations for one week (number of patients)
  obs =   c(30,   14,   34,   45,   57,   20)
)

# Expected Values, given the owner's estimations
data$exp = data$owner * sum(data$obs)

# view the data
glimpse(data)

# Calculating the chi-squared statistic
chi_statistic = sum( (data$obs - data$exp)**2 / data$exp )
print(chi_statistic)
```

Using this chi_squared variable, we need to compare this to a chi distribution table, and in consideration of an alpha value (usually 0.05) determine if the value is statistically signifigant or not. In order to do this, we will also need to know the degreef of freedom, which is the number of independent variables, minus one - in this case: 6.

Summary of important variables:

- Alpha: __0.05__
- Degrees of freedom: __6__

chi_squared chritical values chart

probability \\ Degrees Freedom: | 1 | 2 | 3 | 4 | 5
------------|---|---|---|---|---
0.05        |3.84|5.99|7.82|9.49|11.1
0.01        |6.64|9.21|11.3|13.2|15.1
0.001       |10.8|13.8|16.3|18.5|20.5

Our critical values is __11.1__. Our chi_squared statistic is __11.44__. Our chi-squared statistic is more extreme than the critical value, which means in this case, we would reject the null hypothesis.

## Doing it all in R

This is outside of the scope of the original lesson, but I wanted to supplement the material with an example of how this would look in R - using the built in funcitons. Although, doing this more manually was not that hard either way.

```{r}
# x = the observed counts
# p = the given probabilities
Xsq <- chisq.test(x=data$obs, p=data$owner,correct=F)
Xsq$expected
summary(Xsq)
```

# Chi-Squared Test of Independence

Lesson material [JBStatistics](https://www.youtube.com/watch?v=L1QPBGoDmT0). 

## What is it?

Chi-Squared test of independence tests if the two categorical (also called nominal) variables have an independent relationship or not.

## Example

Let us imagine that we are conducting a study about college drinking and getting in trouble with the police. First, we collect some data and after getting survey responses and possibly some police reports, we get a handle on the following data.

```{r}
# data
drinking_data <- as.table(rbind(
   c(71, 154, 398), 
  c(4992, 2808, 2737) 
))

# naming the dimensions
dimnames(drinking_data) <- list(
  police = c('trouble', 'no trouble'),
  drinking = c('Never', 'Occasionaly', 'Frequently')
)
```

First, in an effort to have a better base understanding, we will cover, what it looks like to do a more manual calculation.

steps:

1. Calculate the expected values
2. Calculate the chi-squared statistic (X<sup>2</sup>)
3. Calculate the degrees freedom (df)

```{r}
sum_of_rows = rowSums(drinking_data)
sum_of_columns = colSums(drinking_data)
total = sum(sum_of_rows)



```

print(drinking_data)

chisq.test(drinking_data, correct=F)

```

